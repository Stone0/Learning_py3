{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 爬取mc头颅信息\n",
    "### `https://minecraft-heads.com/player-heads/food-drinks`\n",
    "### `https://minecraft-heads.com/custom-heads/food-drinks`\n",
    "### `https://minecraft-heads.com/dictionary`\n",
    "### `https://freshcoal.com/maincollection.php`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "import datetime\n",
    "import time\n",
    "import pandas as pd\n",
    "import os\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 打开网页\n",
    "def open_window(url):\n",
    "    # 指定无界面形式运行\n",
    "    chromeOptions = webdriver.ChromeOptions()\n",
    "    chromeOptions.add_argument('--headless')\n",
    "    # driver = webdriver.Chrome(chrome_options=chromeOptions)\n",
    "    driver = webdriver.Chrome()\n",
    "    driver.get(url)\n",
    "    return driver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 爬取公告当前页的基本信息\n",
    "def get_text(driver, flag):\n",
    "    if flag == 0:\n",
    "        # 一采供应商\n",
    "        df_ancm = pd.DataFrame(columns=[\"公告类型\", \"标题\", \"时间\", \"链接\"])\n",
    "    elif flag == 1:\n",
    "        # 二采供应商\n",
    "        df_ancm = pd.DataFrame(columns=[\"公告类型\", \"公告发布单位\", \"标题\", \"时间\", \"链接\"])\n",
    "    else:\n",
    "        # 招标采购\n",
    "        df_ancm = pd.DataFrame(columns=[\"采购需求单位\", \"公告类型\", \"标题\", \"时间\", \"链接\"])\n",
    "\n",
    "    # 爬取当前页的所有[单位 类型 标题 时间]\n",
    "    allAncm = driver.find_elements_by_xpath('//*[@id=\"searchResult\"]/table/tbody/tr')\n",
    "\n",
    "    # 公告内容所有id\n",
    "    pageTitleId = []\n",
    "\n",
    "    for i in range(2, allAncm.__len__()):\n",
    "        ancm = allAncm[i].text\n",
    "        print('  |-' + i.__str__() + ancm)\n",
    "        # 获取公告详细标题\n",
    "        title = allAncm[i].find_element_by_tag_name('a').get_attribute('title')\n",
    "\n",
    "        # 缓存所有标题id\n",
    "        idStr = allAncm[i].get_attribute('onclick')\n",
    "        id = idStr[idStr.find('\\'')+1:idStr.rfind('\\'')]\n",
    "        pageTitleId.append(id)\n",
    "\n",
    "        # 分割标题分别获取[单位 类型 标题 时间]\n",
    "        # 时间\n",
    "        indexTime = ancm.rindex(' ')\n",
    "        ancmTime = ancm[indexTime+1:]\n",
    "\n",
    "        if flag == 0:\n",
    "            # 一采供应商\n",
    "            # 标题\n",
    "            index0 = ancm.index(' ')\n",
    "            ancmTitle = ancm[index0+1:indexTime]\n",
    "            # 链接\n",
    "            ancmLink = 'https://b2b.10086.cn/b2b/main/viewVendorNoticeContent.html?noticeBean.id=' + id\n",
    "\n",
    "            # 保存到df\n",
    "            ancmList = [{\"公告类型\": '一采供应商公告', \"标题\": title if title else ancmTitle, \"时间\": ancmTime, \"链接\": ancmLink}]\n",
    "            df_ancm = df_ancm.append(pd.DataFrame(ancmList, columns=[\"公告类型\", \"标题\", \"时间\", \"链接\"]),\n",
    "                                     ignore_index=True)\n",
    "        elif flag == 1:\n",
    "            # 二采供应商\n",
    "            # 公告发布单位\n",
    "            index0 = ancm.index(' ')\n",
    "            index1 = ancm.index(' ', index0+1)\n",
    "            ancmUnit = ancm[index0:index1]\n",
    "            # 标题\n",
    "            ancmTitle = ancm[index1+1:indexTime]\n",
    "            # 链接\n",
    "            ancmLink = 'https://b2b.10086.cn/b2b/main/viewVendorNoticeContent.html?noticeBean.id=' + id\n",
    "\n",
    "            # 保存到df\n",
    "            ancmList = [{\"公告类型\": '二采供应商公告', \"公告发布单位\": ancmUnit,\n",
    "                         \"标题\": title if title else ancmTitle, \"时间\": ancmTime, \"链接\": ancmLink}]\n",
    "            df_ancm = df_ancm.append(pd.DataFrame(ancmList, columns=[\"公告类型\", \"公告发布单位\", \"标题\", \"时间\", \"链接\"]),\n",
    "                                     ignore_index=True)\n",
    "        else:\n",
    "            # 招标采购\n",
    "            # 单位\n",
    "            index0 = ancm.index(' ')\n",
    "            ancmUnit = ancm[:index0]\n",
    "            # 类型\n",
    "            index1 = ancm.index(' ', index0+1)\n",
    "            ancmType = ancm[index0+1:index1]\n",
    "            # 标题\n",
    "            ancmTitle = ancm[index1+1:indexTime]\n",
    "            # 链接\n",
    "            ancmLink = 'https://b2b.10086.cn/b2b/main/viewNoticeContent.html?noticeBean.id=' + id\n",
    "\n",
    "            # 保存到df\n",
    "            ancmList = [{\"采购需求单位\": ancmUnit, \"公告类型\": ancmType,\n",
    "                         \"标题\": title if title else ancmTitle, \"时间\": ancmTime, \"链接\": ancmLink}]\n",
    "            df_ancm = df_ancm.append(pd.DataFrame(ancmList, columns=[\"采购需求单位\", \"公告类型\", \"标题\", \"时间\", \"链接\"]),\n",
    "                                     ignore_index=True)\n",
    "    return pageTitleId, df_ancm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 爬取所有公告的具体内容\n",
    "def get_content(contentUrl, allTitleId):\n",
    "    chromeOptions = webdriver.ChromeOptions()\n",
    "    chromeOptions.add_argument('--headless')\n",
    "    driver = webdriver.Chrome(chrome_options=chromeOptions)\n",
    "    contentList = []\n",
    "    i = 1\n",
    "    for id in allTitleId:\n",
    "        driver.get(contentUrl + str(id))\n",
    "        print('公告内容' + i.__str__() + ' : ' + id + ' : ' + driver.find_element_by_xpath(\n",
    "            '//*[@id=\"container\"]/div[1]/table/tbody/tr[2]').text)\n",
    "        # time.sleep(0.5)\n",
    "        i += 1\n",
    "        content = driver.find_element_by_xpath('//*[@id=\"container\"]/div[1]/table/tbody')\n",
    "        # 缓存公告内容\n",
    "        contentList.append(content.text)\n",
    "    driver.close()\n",
    "    return contentList\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 搜索两个日期间的所有公告\n",
    "def dateSearch(driver, startDate, endDate):\n",
    "    print('公告日期: ' + startDate + ' - ' + endDate)\n",
    "    driver.find_element_by_xpath('//*[@id=\"startDate\"]').send_keys(startDate)\n",
    "    driver.find_element_by_xpath('//*[@id=\"endDate\"]').send_keys(endDate)\n",
    "    driver.find_element_by_xpath('//*[@id=\"search\"]').click()\n",
    "    time.sleep(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 爬取所有招标采购公告\n",
    "def get_zbcgAncm(driver, filePath, startDate, endDate):\n",
    "    # 获取所有公告类型\n",
    "    allAncmType = driver.find_elements_by_xpath('//*[@id=\"container\"]/div[1]/table/tbody/tr/td[1]/ul/li')\n",
    "\n",
    "    # 搜索两个日期间的所有公告\n",
    "    print('开始搜索公告...')\n",
    "    dateSearch(driver, startDate, endDate)\n",
    "    print('公告搜索完成...')\n",
    "\n",
    "    # 循环爬取所有类型公告\n",
    "    for i in range(allAncmType.__len__()):\n",
    "        # 点击公告类型\n",
    "        print('开始搜索' + allAncmType[i].text + '...')\n",
    "        allAncmType[i].click()\n",
    "        time.sleep(5)\n",
    "\n",
    "        # 当前类型公告df\n",
    "        df_thisAncm = pd.DataFrame(columns=[\"采购需求单位\", \"公告类型\", \"标题\", \"时间\", \"链接\", \"公告内容\"])\n",
    "\n",
    "        # 判断是否为空\n",
    "        tb = driver.find_element_by_xpath('//*[@id=\"searchResult\"]').text\n",
    "        # 未加载完全\n",
    "        while tb == '':\n",
    "            print('请稍等...')\n",
    "            time.sleep(1)\n",
    "\n",
    "        if tb == '查无结果！':\n",
    "            print('数据为空...')\n",
    "            # 保存到csv\n",
    "            df_thisAncm.to_csv(filePath + str(i) + allAncmType[i].text + '.csv', encoding='utf-8-sig', index=False)\n",
    "            continue\n",
    "\n",
    "        # 判断日期是否正确\n",
    "        ancmDate = driver.find_element_by_xpath('//*[@id=\"searchResult\"]/table/tbody/tr[3]/td[4]')\n",
    "        dateTmp = time.strftime('%Y-%m-%d', time.strptime(ancmDate.text, '%Y-%m-%d'))\n",
    "        while dateTmp != endDate and dateTmp > endDate:\n",
    "            print('重新获取日期...')\n",
    "            driver.find_element_by_xpath('//*[@id=\"search\"]').click()\n",
    "            time.sleep(3)\n",
    "            ancmDate = driver.find_element_by_xpath('//*[@id=\"searchResult\"]/table/tbody/tr[3]/td[4]')\n",
    "            dateTmp = time.strftime('%Y-%m-%d', time.strptime(ancmDate.text, '%Y-%m-%d'))\n",
    "\n",
    "        # 判断公告是否点击成功\n",
    "        ancmType = driver.find_element_by_xpath('//*[@id=\"searchResult\"]/table/tbody/tr[3]/td[2]')\n",
    "        while ancmType.text != allAncmType[i].text:\n",
    "            print('重新获取公告...')\n",
    "            allAncmType[i].click()\n",
    "            time.sleep(5)\n",
    "            ancmType = driver.find_element_by_xpath('//*[@id=\"searchResult\"]/table/tbody/tr[3]/td[2]')\n",
    "\n",
    "        # 开始爬取数据\n",
    "        print('开始爬取' + allAncmType[i].text)\n",
    "        j = 1\n",
    "        allTitleId = []\n",
    "        df_content = pd.DataFrame()\n",
    "        while True:\n",
    "            # 爬取当前页的公告\n",
    "            print('开始爬取第' + j.__str__() + '页公告...')\n",
    "            while True:\n",
    "                try:\n",
    "                    pageTitleId, df_ancm = get_text(driver, 2)\n",
    "                    # 判断是否重复爬取\n",
    "                    if j > 1 and pageTitleId[-1] == allTitleId[-1]:\n",
    "                        raise Exception\n",
    "                    allTitleId = pageTitleId\n",
    "                    df_thisAncm = df_thisAncm.append(df_ancm, ignore_index=True)\n",
    "                    break\n",
    "                except Exception as e:\n",
    "                    # print(e)\n",
    "                    print('重新爬取第' + j.__str__() + '页公告...')\n",
    "                    time.sleep(3)\n",
    "            j += 1\n",
    "\n",
    "            print('开始爬取公告具体内容...')\n",
    "            contentUrl = 'https://b2b.10086.cn/b2b/main/viewNoticeContent.html?noticeBean.id='\n",
    "            allContent = get_content(contentUrl, allTitleId)\n",
    "            print('公告内容爬取完成...')\n",
    "\n",
    "            print('开始合并基本信息和公告内容...')\n",
    "            # 公告内容df\n",
    "            df_content = df_content.append(pd.DataFrame(allContent), ignore_index=True)\n",
    "            # 合并基本信息和公告内容并保存\n",
    "            df_thisAncm['公告内容'] = df_content\n",
    "\n",
    "            # 保存为csv\n",
    "            df_thisAncm.to_csv(filePath + str(i) + allAncmType[i].text + '.csv', encoding='utf-8-sig', index=False,\n",
    "                               columns=[\"采购需求单位\", \"公告类型\", \"标题\", \"时间\", \"链接\", \"公告内容\"])\n",
    "            print('合并基本信息和公告内容完成...')\n",
    "\n",
    "            # 点击下一页\n",
    "            try:\n",
    "                driver.find_element_by_xpath('//*[@id=\"pageid2\"]/table/tbody/tr/td[4]/a').click()\n",
    "                time.sleep(3)\n",
    "            except:\n",
    "                print('所有页爬取完成...')\n",
    "                break\n",
    "        print('共' + str(allTitleId.__len__()) + '篇公告...')\n",
    "        print('保存' + allAncmType[i].text + '完成...')\n",
    "    print('所有公告爬取完成...')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 爬取所有供应商公告\n",
    "def get_gysAncm(driver, filePath, startDate, endDate):\n",
    "    # 获取所有供应商公告\n",
    "    allGysType = driver.find_elements_by_xpath('//*[@id=\"container\"]/div[1]/table/tbody/tr/td[1]/ul[2]/li')\n",
    "\n",
    "    # 循环爬取供应商公告\n",
    "    for i in range(allGysType.__len__()):\n",
    "        # 点击公告类型\n",
    "        print('开始搜索' + allGysType[i].text + '...')\n",
    "        allGysType[i].click()\n",
    "        time.sleep(5)\n",
    "\n",
    "        # 搜索两个日期间的所有公告\n",
    "        print('开始搜索公告...')\n",
    "        dateSearch(driver, startDate, endDate)\n",
    "        print('公告搜索完成...')\n",
    "\n",
    "        # 当前类型公告df\n",
    "        if i == 0:\n",
    "            df_thisAncm = pd.DataFrame(columns=[\"公告类型\", \"标题\", \"时间\", \"链接\"])\n",
    "        else:\n",
    "            df_thisAncm = pd.DataFrame(columns=[\"公告类型\", \"公告发布单位\", \"标题\", \"时间\", \"链接\"])\n",
    "\n",
    "        # 判断是否为空\n",
    "        tb = driver.find_element_by_xpath('//*[@id=\"searchResult\"]').text\n",
    "        # 未加载完全\n",
    "        while tb == '':\n",
    "            print('请稍等...')\n",
    "            time.sleep(1)\n",
    "\n",
    "        if tb == '查无结果！':\n",
    "            print('数据为空...')\n",
    "            # 保存到csv\n",
    "            df_thisAncm.to_csv(filePath + str(6+i) + allGysType[i].text + '.csv',\n",
    "                               encoding='utf-8-sig', index=False)\n",
    "            continue\n",
    "\n",
    "        # 判断日期是否正确\n",
    "        tmpAncm = driver.find_element_by_xpath('//*[@id=\"searchResult\"]/table/tbody/tr[3]').text\n",
    "        ancmDate = tmpAncm[tmpAncm.rfind(' ')+1:]\n",
    "        dateTmp = time.strftime('%Y-%m-%d', time.strptime(ancmDate, '%Y-%m-%d'))\n",
    "        while dateTmp != endDate and dateTmp > endDate:\n",
    "            print('重新获取日期...')\n",
    "            driver.find_element_by_xpath('//*[@id=\"search\"]').click()\n",
    "            time.sleep(3)\n",
    "            tmpAncm = driver.find_element_by_xpath('//*[@id=\"searchResult\"]/table/tbody/tr[3]')\n",
    "            ancmDate = tmpAncm[tmpAncm.rfind(' ')+1:]\n",
    "            dateTmp = time.strftime('%Y-%m-%d', time.strptime(ancmDate, '%Y-%m-%d'))\n",
    "\n",
    "        # 开始爬取数据\n",
    "        print('开始爬取' + allGysType[i].text)\n",
    "        # 当前类型公告df\n",
    "        if i == 0:\n",
    "            df_thisAncm = pd.DataFrame(columns=[\"公告类型\", \"标题\", \"时间\", \"链接\"])\n",
    "        else:\n",
    "            df_thisAncm = pd.DataFrame(columns=[\"公告类型\", \"公告发布单位\", \"标题\", \"时间\", \"链接\"])\n",
    "        j = 1\n",
    "        allTitleId = []\n",
    "        df_content = pd.DataFrame()\n",
    "        while True:\n",
    "            # 爬取当前页的公告\n",
    "            print('开始爬取第' + j.__str__() + '页公告...')\n",
    "            while True:\n",
    "                try:\n",
    "                    pageTitleId, df_ancm = get_text(driver, i)\n",
    "                    # 判断是否重复爬取\n",
    "                    if j > 1 and pageTitleId[-1] == allTitleId[-1]:\n",
    "                        raise Exception\n",
    "                    allTitleId += pageTitleId\n",
    "                    df_thisAncm = df_thisAncm.append(df_ancm, ignore_index=True)\n",
    "                    break\n",
    "                except Exception as e:\n",
    "                    # print(e)\n",
    "                    print('重新爬取第' + j.__str__() + '页公告...')\n",
    "                    time.sleep(3)\n",
    "            j += 1\n",
    "\n",
    "            print('开始爬取公告具体内容...')\n",
    "            contentUrl = 'https://b2b.10086.cn/b2b/main/viewVendorNoticeContent.html?noticeBean.id='\n",
    "            allContent = get_content(contentUrl, allTitleId)\n",
    "            print('公告内容爬取完成...')\n",
    "\n",
    "            print('开始合并基本信息和公告内容...')\n",
    "            # 公告内容df\n",
    "            df_content = df_content.append(pd.DataFrame(allContent), ignore_index=True)\n",
    "            # 合并基本信息和公告内容并保存\n",
    "            df_thisAncm['公告内容'] = df_content\n",
    "\n",
    "            if i == 0:\n",
    "                dfcolumns = [\"公告类型\", \"标题\", \"时间\", \"链接\", \"公告内容\"]\n",
    "            else:\n",
    "                dfcolumns = [\"公告类型\", \"公告发布单位\", \"标题\", \"时间\", \"链接\", \"公告内容\"]\n",
    "\n",
    "            # 保存为csv\n",
    "            df_thisAncm.to_csv(filePath + str(6+i) + allGysType[i].text + '.csv',\n",
    "                               encoding='utf-8-sig', index=False, columns=dfcolumns)\n",
    "            print('合并基本信息和公告内容完成...')\n",
    "\n",
    "            # 点击下一页\n",
    "            try:\n",
    "                driver.find_element_by_xpath('//*[@id=\"pageid2\"]/table/tbody/tr/td[4]/a').click()\n",
    "                time.sleep(3)\n",
    "            except:\n",
    "                print('基本信息爬取完成...')\n",
    "                break\n",
    "        print('共' + str(allTitleId.__len__()) + '篇公告...')\n",
    "        print(allGysType[i].text + '爬取完成...')\n",
    "    print('所有公告爬取完成...')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 合并csv\n",
    "def merge_allAncm(filePath, startDate, endDate):\n",
    "    allFile = os.listdir(filePath)\n",
    "\n",
    "    # 设定文件名前缀\n",
    "    seDate = startDate.replace('-', '')[4:] + '-' + endDate.replace('-', '')[4:]\n",
    "\n",
    "    writer = pd.ExcelWriter(filePath + seDate +'招标及供应商公告.xlsx')\n",
    "    print('开始合并csv...')\n",
    "    for i in range(allFile.__len__()):\n",
    "        tmpPath = filePath + allFile[i]\n",
    "        fileSize = os.path.getsize(tmpPath)\n",
    "        sheetName = allFile[i][1:-4]\n",
    "        if fileSize:\n",
    "            tmpDf = pd.read_csv(tmpPath, encoding='utf-8-sig', engine='python')\n",
    "            tmpDf.to_excel(writer, encoding='utf-8-sig', index=False, sheet_name=sheetName)\n",
    "    print('合并csv完成...')\n",
    "    writer.save()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 转移文件\n",
    "def move_file(filePath, startDate, endDate, moveFilePath):\n",
    "    # 创建目录\n",
    "    seDate = startDate.replace('-', '')[4:] + '-' + endDate.replace('-', '')[4:]\n",
    "    dir = moveFilePath + seDate\n",
    "    if not os.path.exists(dir):\n",
    "        os.mkdir(dir)\n",
    "        print('创建目录成功: ' + dir)\n",
    "    else:\n",
    "        print('目录已存在...')\n",
    "\n",
    "    # 转移文件\n",
    "    allFile = os.listdir(filePath)\n",
    "    if not allFile:\n",
    "        print('没有文件可转移...')\n",
    "        return\n",
    "\n",
    "    for i in range(len(allFile)):\n",
    "        shutil.move(filePath + allFile[i], dir)\n",
    "        print(allFile[i] + '移动完成...')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(filePath, startDate, endDate):\n",
    "    print('----- 开始爬虫任务 -----')\n",
    "    driver = open_window('https://b2b.10086.cn/b2b/main/listVendorNotice.html?noticeType=2#this')\n",
    "\n",
    "    # 爬取所有招标采购公告\n",
    "    print('开始爬取招标采购公告...')\n",
    "    get_zbcgAncm(driver, filePath, startDate, endDate)\n",
    "    print('爬取招标采购公告完成...')\n",
    "\n",
    "    # 爬取所有供应商公告\n",
    "    driver.get('https://b2b.10086.cn/b2b/main/preSupplierManagement.html#this')\n",
    "    print('开始爬取供应商公告...')\n",
    "    get_gysAncm(driver, filePath, startDate, endDate)\n",
    "    print('爬取供应商公告完成...')\n",
    "\n",
    "    # 合并csv\n",
    "    print('开始合并公告到xlsx...')\n",
    "    merge_allAncm(filePath, startDate, endDate)\n",
    "    print('合并公告到xlsx完成...')\n",
    "\n",
    "    # 转移文件\n",
    "    print('开始转移文件...')\n",
    "    moveFilePath = r'C:\\PythonProject\\移动公告采集\\\\'\n",
    "    move_file(filePath, startDate, endDate, moveFilePath)\n",
    "    print('转移文件完成...')\n",
    "\n",
    "    print('----- 爬虫任务结束 -----')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    startDate = '2019-04-16'\n",
    "    endDate = '2019-04-22'\n",
    "    filePath = r'C:\\PythonProject\\ChinaMobile\\\\'\n",
    "    main(filePath, startDate, endDate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
